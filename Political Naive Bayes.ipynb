{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/travis/naive-bayes-text-classifier\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "\n",
    "\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# It's handy to have a full set of emojis\n",
    "all_language_emojis = set()\n",
    "\n",
    "def is_emoji(s):\n",
    "    return(emoji.is_emoji(s))\n",
    "\n",
    "def contains_emoji(s):    \n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "    return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    return[t for t in tokens if t.lower() not in sw]\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)\n",
    "\n",
    "def restring(text) :\n",
    "    return (\" \".join(text))\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "def remove_title(text):\n",
    "    text = str(text)\n",
    "    text = text.split('\"',2)[2]\n",
    "    return(text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    'select text, party from conventions'\n",
    ")\n",
    "for row in query_results:\n",
    "    convention_data.append(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yep. 15, close to 15 years cancer free?', 'Democratic'),\n",
       " ('A threat to this nation, to our democracy is real. It’s clear and it’s present. We’ve watched the president now for three years. Look at what he’s doing, instilling fear. I mean, not joking. Instilling fear. Showing division, stroking racial division, undercutting every institution that was designed to check the abuse of power by the president or anyone else. All this for what reason? All this in order to solidify his base and expand his power.',\n",
       "  'Democratic'),\n",
       " ('Good evening. My name is Jeff Van Drew. I speak to you as a member of the Republican Party, but it always wasn’t that way. How I became a Republican says a lot about today’s Democratic Party. I’m from South Jersey, where we work hard, look after our neighbors, and care about our communities. Years ago, I was a local dentist and was asked by the Democrats to run for a town council seat. I had my doubts and I explained that my views were middle of the road to conservative, but the local leaders said the Democratic Party was a big tent and that they accepted people like me. I was elected to council as a Democrat, but as I won seats for county office, state legislature, and then Congress, I noticed things were changing. The Democratic Party had become less accepting of American tradition, less believing in American exceptionalism, less supportive of traditional faith and family. This was not the party that I knew.',\n",
       "  'Republican'),\n",
       " ('Separation of families and children are detrimental to their health.',\n",
       "  'Democratic'),\n",
       " ('But you also know that I care about this nation. You know how much I care about all of our children. So if you take one thing from my words tonight, it is this. If you think things cannot possibly get worse, trust me, they can and they will if we don’t make a change in this election. If we have any hope of ending this chaos, we have got to vote for Joe Biden like our lives depend on it.',\n",
       "  'Democratic'),\n",
       " ('We are going to lift the restrictions on the production of American energy. We will create millions of more jobs.',\n",
       "  'Republican'),\n",
       " ('I work at a meatpacking plant, making sure grocery store shelves stay full. They call us essential workers, but we get treated like we’re expendable. Workers are dying from COVID and a lot of us don’t have paid sick leave or even quality protective equipment. We are human beings, not robots, not disposable. We want to keep helping you feed your family, but we need a President who will have our backs. Nebraska cast 33 votes for our next President, Joe Biden.',\n",
       "  'Democratic'),\n",
       " ('When COVID shut down my college, I came home to my parents’ ranch to finish senior year online. But some days, I can’t even get a video to load or an email attachment to send. Without reliable internet, there’s no remote learning, no virtual doctor’s appointments, and just try starting a small business. Rural broadband can be a game changer for rural communities like mine, and Joe Biden has a plan to make it happen. Montana cast 1 vote for Bernie Sanders and 18 votes for our next President, Joe Biden.',\n",
       "  'Democratic'),\n",
       " ('The morning after the last election I said we owe Donald Trump and open mind and the chance to lead, I meant it. Every president deserves that. And Trump came in with so much set up for him. A strong economy, plans for managing crises including a pandemic. Yes, we Democrats would have disagreed with him on many things, but if he had put his own interests and ego aside, seeing the humanity in a child ripped from her parents at the border or a protestor calling for justice or a family wiped out by natural disaster, that would have been a good thing for America and the world. I wish Donald Trump knew how to be a president because America needs a president right now. Throughout this time of crisis Americans keep going, checking on neighbors, showing up to jobs as first responders, hospitals, grocery stores, nursing homes. Yes, it still takes a village and we need leaders equal to this moment of sacrifice and service.',\n",
       "  'Democratic'),\n",
       " ('It’s normally called by the parents, I would say. But this time it was called by me.',\n",
       "  'Democratic')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the list into a two column DataFrame for the Convention Data\n",
    "df = pd.DataFrame(convention_data, columns = ['Text', 'Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This pipeline was recycled from the previous modules work and I added \"restring\"\n",
    "#on the end to put tokens back together into a string format after removing stopwords\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop, restring]\n",
    "\n",
    "#Running the Tweet data through the pipeline\n",
    "df[\"Text\"] = df[\"Text\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2275 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "\n",
    "tokens = []\n",
    "\n",
    "# Cycling through the Text columns data to test the amount of features output\n",
    "for i in df[\"Text\"]:\n",
    "    i = tokenize(i)\n",
    "    tokens.extend(i)\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "\n",
    "    ret_dict = dict()\n",
    "    #tokenizingthe cleaned text data from the DataFrame\n",
    "    text = tokenize(text)\n",
    "    \n",
    "    #Cycling through the sample data to check against the feature words, returning true if it is in the feature words set\n",
    "    for sample in text:\n",
    "        for tok in fw:\n",
    "            if sample == tok:\n",
    "                ret_dict.update({sample:True})\n",
    "        \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)=={'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)=={'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the feature set for the convention data\n",
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                 company = True           Republ : Democr =     16.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.8 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.2 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "                 liberal = True           Republ : Democr =     10.9 : 1.0\n",
      "                     red = True           Republ : Democr =     10.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 culture = True           Republ : Democr =      9.9 : 1.0\n",
      "                 defense = True           Republ : Democr =      9.9 : 1.0\n",
      "             regulations = True           Republ : Democr =      9.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Your observations to come._\n",
    "\n",
    "What I notice about the classifier is that the bulk of the top 25 features are found in republican speeches. This leads me to believe that there are potentially more republican speeches than Democratic. This could possibly lead to greater inaccuracy due to lower variablility between Democrat and Republican Rhetoric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664656\n"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for row in results:\n",
    "    tweet_data.append(list(row))\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "print(len(tweet_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the first column of the list since we are not using the candidate names\n",
    "for row in tweet_data:\n",
    "    del row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like the convention dataset, I am converting the sample dataset to a DataFrame\n",
    "df_conv = pd.DataFrame(tweet_data_sample, columns = ['Party', 'Text'])\n",
    "\n",
    "#building the dataframe for the full dataset of tweet_data\n",
    "df_full = pd.DataFrame(tweet_data, columns = ['Party', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Decoding both datasets text columns\n",
    "df_conv['Text'] = df_conv['Text'].str.decode(encoding='UTF-8')\n",
    "df_full['Text'] = df_full['Text'].str.decode(encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the pipeline to both datasets, saving the result to a new column \n",
    "#to retain the original string to use for comparison\n",
    "df_conv[\"Token\"] = df_conv[\"Text\"].apply(prepare,pipeline=my_pipeline)\n",
    "df_full[\"Token\"] = df_full[\"Text\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: Earlier today, I spoke on the House Floor abt protecting health care for women and praised @PPmarmonte for their work on the Central Coast. https://t.co/WqgTRzT7VV\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Go Tribe! #RallyTogether https://t.co/0NXutFL9L5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Apparently, Trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #TrumpBudget https://t.co/ckYQO5T0Qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: We’re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\n",
      "\n",
      "https://t.co/eZPv0vMIz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Let’s make it even Greater !! #KAG 🇺🇸 https://t.co/y9qoZD5L2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: We have about 1hr until the @cavs tie up the series 2-2. I'm #ALLin216 @RepBarbaraLee you scared? #roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Congrats to @belliottsd on his new gig at SD City Hall. We are glad you will continue to serve… https://t.co/fkvMw3cqdI\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: We are really close, we have over $3500 raised toward the match right now. Whoot!! (That’s $7000 for the non-math majors in the room 😂). Help us get there https://t.co/Tu34C472sD https://t.co/QsdQkYpsmC\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Today, the comment period for @POTUS’s plan to expand offshore drilling opened to the public. You have 60 days (until March 9) to share why you oppose the proposed program directly with the Trump Administration. Comments can be made by email or mail. https://t.co/BaaYMeJxQn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Celebrated @ICSEastLA’s 22 years of Eastside commitment &amp; saluted community leaders at last night’s awards dinner! https://t.co/7V7gH8giVB\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in df_conv.index:\n",
    "    estimated_party = classifier.classify(conv_features(df_conv['Token'][row],feature_words))\n",
    "    print(f\"Here's our (cleaned) tweet: {df_conv['Text'][row]}\")\n",
    "    print(f\"Actual party is {df_conv['Party'][row]} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "#random.shuffle(test_df)\n",
    "\n",
    "# for idx, tp in enumerate(tweet_data) :\n",
    "#     tweet, party = tp\n",
    "for row in df_full.index:\n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(df_full['Token'][row],feature_words))\n",
    "    \n",
    "    results[df_full['Party'][row]][estimated_party] += 1\n",
    "    \n",
    "    if row > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3508, 'Democratic': 577}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4930, 'Democratic': 987})})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ \n",
    "\n",
    "I noticed that from the results, the model is more has a bias towards classifying an observation as Republican. These results to me seem to be subpar as we have mislabeled nearly 5000 tweets that were not Republican. This could be due to the top 25 most informative features being Republican biased. So if we have a more equal featureset the accuracy could be potentially better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
